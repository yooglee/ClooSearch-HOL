{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d59d527f-1100-45ff-b051-5f7c9029d94d",
   "metadata": {},
   "source": [
    "# Queries with and without Azure OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9a9444-dc90-4fc3-aea7-8ee918301aba",
   "metadata": {},
   "source": [
    "이전 단계들에서는 서로 다른 두 데이터 소스에서 검색 엔진을 로드했습니다. 이번에는 몇 가지 예제 쿼리를 시도한 다음 Azure OpenAI 서비스를 사용하여 더 나은 결과를 얻을 수 있는지 알아보겠습니다.\n",
    "\n",
    "이 **Multi-Index** 데모는 회사가 서로 다른 유형의 문서와 완전히 다른 주제를 로드하고 검색 엔진이 가장 연관성이 높은 결과로 응답해야 하는 시나리오를 모방합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f6c7e3-9037-4b1e-ae17-1deaa27b9c08",
   "metadata": {},
   "source": [
    "## Set up variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e50b404-a061-49e7-a3c7-c6eabc98ff0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import urllib\n",
    "import requests\n",
    "import random\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "from IPython.display import display, HTML, Markdown\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "from common.prompts import COMBINE_QUESTION_PROMPT, COMBINE_PROMPT, COMBINE_PROMPT_TEMPLATE\n",
    "from common.utils import (\n",
    "    get_search_results,\n",
    "    model_tokens_limit,\n",
    "    num_tokens_from_docs,\n",
    "    num_tokens_from_string\n",
    ")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"credentials.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f2c22f8-79ab-405c-95e8-77a1978e53bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the Payloads header\n",
    "headers = {'Content-Type': 'application/json','api-key': os.environ['AZURE_SEARCH_KEY']}\n",
    "params = {'api-version': os.environ['AZURE_SEARCH_API_VERSION']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9297d29b-1f61-4dce-858e-bf4272172dba",
   "metadata": {},
   "source": [
    "## 멀티 검색 인덱스 쿼리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a46e2d3-298a-4708-83de-9e108b1a117a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Text-based Indexes that we are going to query (from Notebook 01 and 02)\n",
    "index1_name = \"cogsrch-index-files\"\n",
    "# indexes = [index1_name]\n",
    "index2_name = \"cogsrch-index-csv\"\n",
    "indexes = [index1_name, index2_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b9b53c14-19bd-451f-aa43-7ad27ccfeead",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION = \"발달상권 가구의 4분기 분기매출을 알려줘\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d925eb-7f9c-429e-a62a-4c37d7702caf",
   "metadata": {},
   "source": [
    "### 두 인덱스를 개별적으로 검색하고 결과를 집계합니다\n",
    "\n",
    "#### **Note**: \n",
    "인덱스들을 표준화하기 위해 각 텍스트 기반 인덱스에 **'id, title, content, chunk, language, name, location, vectorized'** 라는 8개의 필수 필드가 존재해야 합니다. 이는 코드를 따라 각 문서가 동일하게 취급될 수 있도록 하기 위한 것입니다. 또한 모든 인덱스는 의미 구성을 가져야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "faf2e30f-e71f-4533-ab52-27d048b80a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "Index: cogsrch-index-files Results Found: 4, Results Returned: 4\n",
      "200\n",
      "Index: cogsrch-index-csv Results Found: 859, Results Returned: 10\n"
     ]
    }
   ],
   "source": [
    "agg_search_results = dict()\n",
    "\n",
    "for index in indexes:\n",
    "    search_payload = {\n",
    "        \"search\": QUESTION,\n",
    "        \"select\": \"id, title, chunks, language, name, location\",\n",
    "        \"queryType\": \"semantic\",\n",
    "        \"semanticConfiguration\": \"my-semantic-config\",\n",
    "        \"count\": \"true\",\n",
    "        \"speller\": \"lexicon\",\n",
    "        \"queryLanguage\": \"en-us\",\n",
    "        \"captions\": \"extractive\",\n",
    "        \"answers\": \"extractive\",\n",
    "        \"top\": \"10\"\n",
    "    }\n",
    "\n",
    "    r = requests.post(os.environ['AZURE_SEARCH_ENDPOINT'] + \"/indexes/\" + index + \"/docs/search\",\n",
    "                     data=json.dumps(search_payload), headers=headers, params=params)\n",
    "    print(r.status_code)\n",
    "\n",
    "    search_results = r.json()\n",
    "    agg_search_results[index]=search_results\n",
    "    print(\"Index:\", index, \"Results Found: {}, Results Returned: {}\".format(search_results['@odata.count'], len(search_results['value'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fd0fe5-4ee0-42e2-a920-72b93a407389",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Search Score를 기준으로 상위 결과 표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "401ab3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@odata.context': \"https://cog-search-iwdkwba7nutto.search.windows.net/indexes('cogsrch-index-csv')/$metadata#docs(*)\",\n",
       " '@odata.count': 859,\n",
       " '@search.answers': [],\n",
       " 'value': [{'@search.score': 0.00809721,\n",
       "   '@search.rerankerScore': 1.9352405071258545,\n",
       "   '@search.captions': [{'text': '4분기.', 'highlights': ''}],\n",
       "   'id': 'YH37',\n",
       "   'title': None,\n",
       "   'chunks': [],\n",
       "   'language': None,\n",
       "   'name': '시계및귀금속',\n",
       "   'location': '종로4가'},\n",
       "  {'@search.score': 0.00809721,\n",
       "   '@search.rerankerScore': 1.9352405071258545,\n",
       "   '@search.captions': [{'text': '4분기.', 'highlights': None}],\n",
       "   'id': 'YH358',\n",
       "   'title': None,\n",
       "   'chunks': [],\n",
       "   'language': None,\n",
       "   'name': '가전제품',\n",
       "   'location': '방학1동주민센터'},\n",
       "  {'@search.score': 0.00809721,\n",
       "   '@search.rerankerScore': 1.9352405071258545,\n",
       "   '@search.captions': [{'text': '4분기.', 'highlights': None}],\n",
       "   'id': 'YH377',\n",
       "   'title': None,\n",
       "   'chunks': [],\n",
       "   'language': None,\n",
       "   'name': '시계및귀금속',\n",
       "   'location': '면목역 3번'},\n",
       "  {'@search.score': 0.00809721,\n",
       "   '@search.rerankerScore': 1.9352405071258545,\n",
       "   '@search.captions': [{'text': '4분기.', 'highlights': None}],\n",
       "   'id': 'YH402',\n",
       "   'title': None,\n",
       "   'chunks': [],\n",
       "   'language': None,\n",
       "   'name': '시계및귀금속',\n",
       "   'location': '장안제일시장'},\n",
       "  {'@search.score': 0.00809721,\n",
       "   '@search.rerankerScore': 1.9352405071258545,\n",
       "   '@search.captions': [{'text': '4분기.', 'highlights': None}],\n",
       "   'id': 'YH408',\n",
       "   'title': None,\n",
       "   'chunks': [],\n",
       "   'language': None,\n",
       "   'name': '시계및귀금속',\n",
       "   'location': '신월2동주민센터'},\n",
       "  {'@search.score': 0.00809721,\n",
       "   '@search.rerankerScore': 1.9352405071258545,\n",
       "   '@search.captions': [{'text': '4분기.', 'highlights': None}],\n",
       "   'id': 'YH425',\n",
       "   'title': None,\n",
       "   'chunks': [],\n",
       "   'language': None,\n",
       "   'name': '시계및귀금속',\n",
       "   'location': '문정역 2번'},\n",
       "  {'@search.score': 0.00809721,\n",
       "   '@search.rerankerScore': 1.9352405071258545,\n",
       "   '@search.captions': [{'text': '4분기.', 'highlights': None}],\n",
       "   'id': 'YH426',\n",
       "   'title': None,\n",
       "   'chunks': [],\n",
       "   'language': None,\n",
       "   'name': '가구',\n",
       "   'location': '신림역 8번'},\n",
       "  {'@search.score': 0.00809721,\n",
       "   '@search.rerankerScore': 1.9352405071258545,\n",
       "   '@search.captions': [{'text': '4분기.', 'highlights': None}],\n",
       "   'id': 'YH432',\n",
       "   'title': None,\n",
       "   'chunks': [],\n",
       "   'language': None,\n",
       "   'name': '시계및귀금속',\n",
       "   'location': '사당역 10번'},\n",
       "  {'@search.score': 0.00809721,\n",
       "   '@search.rerankerScore': 1.9352405071258545,\n",
       "   '@search.captions': [{'text': '4분기.', 'highlights': None}],\n",
       "   'id': 'YH459',\n",
       "   'title': None,\n",
       "   'chunks': [],\n",
       "   'language': None,\n",
       "   'name': '시계및귀금속',\n",
       "   'location': '서대문역'},\n",
       "  {'@search.score': 0.00809721,\n",
       "   '@search.rerankerScore': 1.9352405071258545,\n",
       "   '@search.captions': [{'text': '4분기.', 'highlights': None}],\n",
       "   'id': 'YH462',\n",
       "   'title': None,\n",
       "   'chunks': [],\n",
       "   'language': None,\n",
       "   'name': '가구',\n",
       "   'location': '성수대교남단'}]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_search_results[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9e938337-602d-4b61-8141-b8c92a5d91da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Top Answers</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Top Results</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5><a href=\"종로4가?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2024-11-17T10:00:20Z&st=2023-10-17T02:00:20Z&spr=https&sig=A70wSmXw2q4gtqHFKd8h4J54rSkDp41DnyIXTFQ265A%3D\">시계및귀금속</a> - score: 1.94</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "4분기."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5><a href=\"방학1동주민센터?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2024-11-17T10:00:20Z&st=2023-10-17T02:00:20Z&spr=https&sig=A70wSmXw2q4gtqHFKd8h4J54rSkDp41DnyIXTFQ265A%3D\">가전제품</a> - score: 1.94</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "4분기."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5><a href=\"면목역 3번?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2024-11-17T10:00:20Z&st=2023-10-17T02:00:20Z&spr=https&sig=A70wSmXw2q4gtqHFKd8h4J54rSkDp41DnyIXTFQ265A%3D\">시계및귀금속</a> - score: 1.94</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "4분기."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5><a href=\"장안제일시장?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2024-11-17T10:00:20Z&st=2023-10-17T02:00:20Z&spr=https&sig=A70wSmXw2q4gtqHFKd8h4J54rSkDp41DnyIXTFQ265A%3D\">시계및귀금속</a> - score: 1.94</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "4분기."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5><a href=\"신월2동주민센터?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2024-11-17T10:00:20Z&st=2023-10-17T02:00:20Z&spr=https&sig=A70wSmXw2q4gtqHFKd8h4J54rSkDp41DnyIXTFQ265A%3D\">시계및귀금속</a> - score: 1.94</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "4분기."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5><a href=\"문정역 2번?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2024-11-17T10:00:20Z&st=2023-10-17T02:00:20Z&spr=https&sig=A70wSmXw2q4gtqHFKd8h4J54rSkDp41DnyIXTFQ265A%3D\">시계및귀금속</a> - score: 1.94</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "4분기."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5><a href=\"신림역 8번?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2024-11-17T10:00:20Z&st=2023-10-17T02:00:20Z&spr=https&sig=A70wSmXw2q4gtqHFKd8h4J54rSkDp41DnyIXTFQ265A%3D\">가구</a> - score: 1.94</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "4분기."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5><a href=\"사당역 10번?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2024-11-17T10:00:20Z&st=2023-10-17T02:00:20Z&spr=https&sig=A70wSmXw2q4gtqHFKd8h4J54rSkDp41DnyIXTFQ265A%3D\">시계및귀금속</a> - score: 1.94</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "4분기."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5><a href=\"서대문역?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2024-11-17T10:00:20Z&st=2023-10-17T02:00:20Z&spr=https&sig=A70wSmXw2q4gtqHFKd8h4J54rSkDp41DnyIXTFQ265A%3D\">시계및귀금속</a> - score: 1.94</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "4분기."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5><a href=\"성수대교남단?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2024-11-17T10:00:20Z&st=2023-10-17T02:00:20Z&spr=https&sig=A70wSmXw2q4gtqHFKd8h4J54rSkDp41DnyIXTFQ265A%3D\">가구</a> - score: 1.94</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "4분기."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5><a href=\"https://holstorage.blob.core.windows.net/arxivcs/230920_etoday.pdf?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2024-11-17T10:00:20Z&st=2023-10-17T02:00:20Z&spr=https&sig=A70wSmXw2q4gtqHFKd8h4J54rSkDp41DnyIXTFQ265A%3D\">Untitled</a> - score: 1.47</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "주간통계를당장없애기보다보완하는  게바람직하다는견해도있다.김인만부  동산연구소장은 문제가있다고없애는  것은정답이아니고개선해야하는게맞  는다며 진짜문제는정부가목적을갖고  표본수나조사지역등을인위적으로조  작하는것인만큼통계를내는기관이독  립적으로일할수있도록보호해줘야한  다고말했다. 이은형대한건설정책연구원연구위원  도 똑같은대상에대해서복수의기관의  자료를비교할여지가있고검토할측면  이있는게좋다고본다며부동산원주간  통계폐지에부정적의견을냈다."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5><a href=\"https://holstorage.blob.core.windows.net/arxivcs/230921_etoday.pdf?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2024-11-17T10:00:20Z&st=2023-10-17T02:00:20Z&spr=https&sig=A70wSmXw2q4gtqHFKd8h4J54rSkDp41DnyIXTFQ265A%3D\">Untitled</a> - score: 1.11</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "앞서금감원은 7월 21일부터  긴급현장검사에착수했으며지  난달초까지562억원의횡령혐  의를확인했다고밝혔다.경남은  행은 4월부터 자체조사를 했음  에도금감원에77억9000만원의  피해를인지했다고보고했다.이  후 금감원은 추가 검사를 통해  2988억원의횡령액을최종확  인했다.현직에있는직원개인  이저지른금융권횡령사고중  최고액이다. 금감원은이번횡령사고발생  의원인을BNK금융지주와경남  은행의부실한내부통제탓으로  지목했다. 조사결과BNK금융  지주는자회사인경남은행의위  험관리및업무실태점검에소홀  했던것으로드러났다."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML('<h4>Top Answers</h4>'))\n",
    "\n",
    "for index,search_results in agg_search_results.items():\n",
    "    for result in search_results['@search.answers']:\n",
    "        if result['score'] > 0.5: # Show answers that are at least 50% of the max possible score=1\n",
    "            display(HTML('<h5>' + 'Answer - score: ' + str(round(result['score'],2)) + '</h5>'))\n",
    "            display(HTML(result['text']))\n",
    "            \n",
    "print(\"\\n\\n\")\n",
    "display(HTML('<h4>Top Results</h4>'))\n",
    "\n",
    "content = dict()\n",
    "ordered_content = OrderedDict()\n",
    "\n",
    "\n",
    "for index,search_results in agg_search_results.items():\n",
    "    for result in search_results['value']:\n",
    "        if result['@search.rerankerScore'] > 1:# Show answers that are at least 25% of the max possible score=4\n",
    "            content[result['id']]={\n",
    "                                    \"title\": result['title'],\n",
    "                                    \"chunks\": result['chunks'],\n",
    "                                    \"language\": result['language'], \n",
    "                                    \"name\": result['name'], \n",
    "                                    \"location\": result['location'] ,\n",
    "                                    \"caption\": result['@search.captions'][0]['text'],\n",
    "                                    \"score\": result['@search.rerankerScore'],\n",
    "                                    \"index\": index\n",
    "                                    }\n",
    "    \n",
    "#After results have been filtered we will Sort and add them as an Ordered list\\n\",\n",
    "for id in sorted(content, key= lambda x: content[x][\"score\"], reverse=True):\n",
    "    ordered_content[id] = content[id]\n",
    "    url = str(ordered_content[id]['location']) + os.environ['BLOB_SAS_TOKEN']\n",
    "    title = str(ordered_content[id]['title']) if (ordered_content[id]['title']) else ordered_content[id]['name']\n",
    "    score = str(round(ordered_content[id]['score'],2))\n",
    "    display(HTML('<h5><a href=\"'+ url + '\">' + title + '</a> - score: '+ score + '</h5>'))\n",
    "    display(HTML(ordered_content[id]['caption']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df3e6d4-9a09-4b0f-b328-238738ccfaec",
   "metadata": {},
   "source": [
    "# Azure OpenAI 사용\n",
    "\n",
    "검색 결과에서 GPT 모델까지의 답변과 문서 내용을 컨텍스트로 제공하고 더 나은 응답을 제공하기 까지 몇가지 작업을 이해해야 합니다. \n",
    "\n",
    "1) 체인닝 및 신속 엔지니어링\n",
    "2) 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eea62a7d-7e0e-4a93-a89c-20c96560c665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
    "os.environ[\"OPENAI_API_BASE\"] = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325d9138-2250-4f6b-bc88-50d7957f8d33",
   "metadata": {},
   "source": [
    "**Important Note**\n",
    "이번 단계부터는 OpenAI 모델을 사용할 예정입니다. Azure OpenAI 포털 내에 아래 모델을 배포했는지 확인하십시오:\n",
    "\n",
    "- text-embedding-ada-002\n",
    "- gpt-35-turbo\n",
    "- gpt-35-turbo-16k\n",
    "- gpt-4\n",
    "- gpt-4-32k\n",
    "\n",
    "만약 위에 주어진 이름 말고 다른 이름으로 모델을 배포했다면 아래에 제공된 코드는 예상대로 작동하지 않습니다. \n",
    "다른 이름으로 배포했다면 모든 코드에서 변수 이름을 수정해야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7c720e-ece1-45ad-9d01-2dfd15c182bb",
   "metadata": {},
   "source": [
    "## LLM 체인과 Prompt Engineering에 대한 간단한 소개"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcd7028-5a6c-4296-8c85-4f420d408d69",
   "metadata": {},
   "source": [
    "체인은 하나 이상의 LLM(Large Language Model)을 논리적인 방식으로 연결함으로써 얻을 수 있는 것으로 Azure OpenAI은 LLM(provider)의 일종입니다. \n",
    "\n",
    "체인은 단순(Generic) 또는 특수(Utility)로 나뉠 수 있으며 이번 단계에서는 단순체인(Generic Chain)을 사용할 것입니다. \n",
    "\n",
    "* Generic — 단일 LLM은 가장 간단한 체인입니다. 입력 프롬프트와 LLM 이름을 사용한 다음 텍스트 생성(즉, 프롬프트의 출력)을 위해 LLM을 사용합니다.\n",
    "\n",
    "예제는 다음과 같습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "13df9247-e784-4e04-9475-55e672efea47",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-4\" # options: gpt-35-turbo, gpt-35-turbo-16k, gpt-4, gpt-4-32k\n",
    "COMPLETION_TOKENS = 2000\n",
    "llm = AzureChatOpenAI(deployment_name=MODEL, temperature=0, max_tokens=COMPLETION_TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7b0520b9-83b2-49fd-ad84-624cb0f15ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following question: \"발달상권 가구의 4분기 분기매출을 알려줘\". Give your response in Korean\n"
     ]
    }
   ],
   "source": [
    "# 이제 간단한 Prompt Template을 만들어 보겠습니다. \n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\", \"language\"],\n",
    "    template='Answer the following question: \"{question}\". Give your response in {language}',\n",
    ")\n",
    "\n",
    "print(prompt.format(question=QUESTION, language=\"Korean\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dcc7dae3-6b88-4ea6-be43-b178ebc559dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': '발달상권 가구의 4분기 분기매출을 알려줘',\n",
       " 'language': 'Korean',\n",
       " 'text': '죄송합니다, 저는 인공지능으로서 실시간 데이터나 특정 회사의 매출 정보를 제공할 수 없습니다. 해당 정보를 얻으려면 관련 기관이나 데이터베이스를 참조하시기 바랍니다.'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 그리고 Prompt Template을 사용하여 간단한 Generic 체인을 만들어 보겠습니다. \n",
    "chain_chat = LLMChain(llm=llm, prompt=prompt)\n",
    "chain_chat({\"question\": QUESTION, \"language\": \"Korean\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8539d0-a538-4368-82c3-5f91d8370f1e",
   "metadata": {},
   "source": [
    "**노트**: 만약 Resource not found 오류가 발생하면 OpenAI 모델 배포 이름이 위의 변수 MODEL 집합과 다르기 때문일 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ed014c-0c6b-448c-b995-fe7970b92ad5",
   "metadata": {},
   "source": [
    "앞서 본 코드로 인해 이제 간단한 프롬프트를 만들고 ChatGPT 지식을 사용하여 일반적인 질문에 답하는 방법을 알게 되었습니다.\n",
    "\n",
    "Generic 체인을 독립 실행형 체인으로 사용하는 경우는 거의 없고 보통 Utility 체인의 구성 요소로 사용되는 경우가 더 많습니다. \n",
    "또한 주목해야 할 점은 아직 문서나 Azure Search의 결과를 사용하지 않고 있으며, 학습한 데이터에 대한 ChatGPT 지식만 사용하고 있다는 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c48038-b1af-4228-8ffb-720e554fd3b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "**두 번째 체인 유형은 Utility 체인입니다:**\n",
    "\n",
    "* Utility — LangChain은 언어 작업을 해결하는데 특화된 여러 LLM으로 구성된 체인입니다. 예를 들어, LangChain은 end-to-end 체인(예: [QA_WITH_SOURCES](https://python.langchain.com/en/latest/modules/chains/index_examples/qa_with_sources.html) for QnA Doc retrieval, Summarization, etc)과 일부 특정 체인 (그래프 생성, 쿼리 및 저장을 위한 GraphQnAChain 등)을 지원합니다. \n",
    "\n",
    "이번 워크샵에서는 **qa_with_sources** 라는 특정 체인을 살펴보고 Azure Cognitive Search의 결과를 향상시키는 사용 사례를 시도해 보겠습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0454ddb-44d8-4fa9-929a-5e5563dd28f8",
   "metadata": {},
   "source": [
    "그러나 utility 체인을 이용할때 가장 큰 문제점은 바로 토큰의 크기 입니다. 많은 검색 결과 파일의 내용이 Azure OpenAI에서 제공하는 GPT 모델의 허용 토큰보다 클 수 있습니다.\n",
    "\n",
    "이것이 해결하기 위해 나온 것이 바로 임베딩/벡터의 개념입니다. \n",
    "\n",
    "## 임베딩과 벡터 검색 \n",
    "\n",
    "임베딩은 기계 학습 모델과 알고리즘에 의해 쉽게 활용될 수 있는 데이터 표현의 특별한 형식입니다. 임베딩은 텍스트의 semantic 정보를 밀도 있게 표현하는 것으로 각 임베딩은 부동 소수점 숫자의 벡터이므로 벡터 공간에서 두 임베딩 사이의 거리가 원래 형식의 두 입력 사이의 의미적 유사성과 상관관계가 있습니다. 예를 들어, 두 텍스트의 의마가 유사한 경우 벡터 표현도 유사해야 합니다.\n",
    "\n",
    "LLM(Language Model)의 토큰 제한 문제를 해결하기 위해 솔루션은 다음 단계를 포함합니다:\n",
    "\n",
    "1. **문서 세분화**: 문서를 더 작은 세그먼트 또는 청크로 나눕니다.\n",
    "2. **청크 벡터화**: 적절한 기술을 사용하여 이러한 청크를 벡터로 변환합니다.\n",
    "3. **벡터 시맨틱 검색**: 주어진 질문과 유사한 상위 청크를 식별하기 위해 벡터를 사용하여 시맨틱 검색을 실행합니다.\n",
    "4. **최적의 컨텍스트 제공**: LLM에 가장 관련성 있고 간결한 컨텍스트를 제공하여 포괄성과 길이 간의 최적의 균형을 달성합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e79235-3d8b-4713-9336-5004cc4a1556",
   "metadata": {},
   "source": [
    "이번 notebook에서의 목표는 벡터 인덱스를 사용하는 것입니다. 다양한 파일 형식에 대해 OCR로 파서를 수동으로 코드화하고 인덱스와 데이터를 동기화할 수 있는 스케줄러를 개발하는 것이 가능하지만, 더 효율적인 대안이 있습니다. \n",
    "\n",
    "1. 청크와 벡터를 벡터 기반 인덱스로 수동으로 푸시합니다.\n",
    "2. 사용자가 필요한 문서를 검색할 때 벡터 기반 인덱스 작성합니다. \n",
    "3. 사용자 지정 기술(청킹 및 벡터화용)을 사용하고 지식 저장소를 사용하여 수집 시점에 텍스트 기반 ai가 풍부한 인덱스에서 벡터 기반 인덱스를 만듭니다. \n",
    "이 작업을 수행하는 방법은 [여기](https://github.com/Azure/cognitive-search-vector-pr/blob/main/demo-python/code/azure-search-vector-ingestion-python-sample.ipynb)에서 확인 가능합니다. \n",
    "\n",
    "이 notebook에서는 옵션 2를 구현할 예정입니다. **각 텍스트 기반 인덱스별로 벡터 기반 인덱스를 생성하고 문서가 검색될 때마다 필요에 따라 인덱스를 채우십시오**. \n",
    "\n",
    "노트 1과 노트 2에서 볼 수 있듯이 각 텍스트 기반 인덱스에는 아직 사용하지 않은 vector화된 필드가 포함되어 있습니다. 이제 이 필드를 활용할 것 입니다. \n",
    "이번 단계의 목적은 수집 시점에 모든 문서를 벡터화하는 것을 피하며(옵션 3) 사용자가 문서를 검색할 때만 문서 청크를 벡터화합니다. 이 접근 방식은 문서가 실제로 필요할 때만 자금과 자원을 할당하기에 일반적으로 Data Lake에 있는 문서 중 20%만 자주 액세스되고 나머지는 손상되지 않은 상태로 유지됩니다. 이 방법론을 [파레토 원칙](https://en.wikipedia.org/wiki/Pareto_principle) 에서 가져왔습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "12682a1b-df92-49ce-a638-7277103f6cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"cogsrch-index-files\"\n",
    "# indexes = [index_name]\n",
    "index2_name = \"cogsrch-index-csv\"\n",
    "indexes = [index_name, index2_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a6d6a7-18ef-45b2-a216-3c1f50006593",
   "metadata": {},
   "source": [
    "코드에서 자주 쓰이는 함수들을 반복하지 않기 위해 common/utils.py 파일과 common/prompts.py 파일 넣어두고 필요할 때 불러 사용하고 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3bccca45-d1dd-476f-b109-a528b857b6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of results: 12\n"
     ]
    }
   ],
   "source": [
    "k = 10 # Number of results per each text_index\n",
    "ordered_results = get_search_results(QUESTION, indexes, k=10, reranker_threshold=1)\n",
    "print(\"Number of results:\",len(ordered_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7714f38a-daaa-4fc5-a95a-dd025d153216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the below line if you want to inspect the ordered results\n",
    "# ordered_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da70e7a8-7536-4688-b30c-01ba28e9b9f8",
   "metadata": {},
   "source": [
    "이제 사용자가 텍스트 기반 인덱스를 사용하여 문서를 검색할 때 벡터 기반 인덱스를 사용할 수 있습니다. 이 접근 방식은 사용자 쿼리당 두 번의 검색(텍스트 기반 인덱스와 벡터 기반 인덱스)이 필요하지만 구현이 더 간단하며 사용자가 시스템을 사용할 때 점점 더 빨라질 것 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2937ba3b-098d-43f8-8498-3534882a5cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = OpenAIEmbeddings(deployment=\"text-embedding-ada-002\", chunk_size=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f664df30-99c3-4a30-8cb0-42ba3044e5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing 0 chunks from Document: 종로4가\n",
      "Vectorizing 0 chunks from Document: 방학1동주민센터\n",
      "Vectorizing 0 chunks from Document: 면목역 3번\n",
      "Vectorizing 0 chunks from Document: 장안제일시장\n",
      "Vectorizing 0 chunks from Document: 신월2동주민센터\n",
      "Vectorizing 0 chunks from Document: 문정역 2번\n",
      "Vectorizing 0 chunks from Document: 신림역 8번\n",
      "Vectorizing 0 chunks from Document: 사당역 10번\n",
      "Vectorizing 0 chunks from Document: 서대문역\n",
      "Vectorizing 0 chunks from Document: 성수대교남단\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for key,value in ordered_results.items():\n",
    "    if value[\"vectorized\"] != True: # 문서가 아직 벡터링되지 않은 경우\n",
    "        i = 0\n",
    "        print(\"Vectorizing\",len(value[\"chunks\"]),\"chunks from Document:\",value[\"location\"])\n",
    "        for chunk in value[\"chunks\"]: # 문서의 텍스트 청크를 반복\n",
    "            try:\n",
    "                upload_payload = {  # 벡터 기반 인덱스에 청크와 벡터 삽입\n",
    "                    \"value\": [\n",
    "                        {\n",
    "                            \"id\": key + \"_\" + str(i),\n",
    "                            \"title\": f\"{value['title']}_chunk_{str(i)}\",\n",
    "                            \"chunk\": chunk,\n",
    "                            \"chunkVector\": embedder.embed_query(chunk if chunk!=\"\" else \"-------\"),\n",
    "                            \"name\": value[\"name\"],\n",
    "                            \"location\": value[\"location\"],\n",
    "                            \"@search.action\": \"upload\"\n",
    "                        },\n",
    "                    ]\n",
    "                }\n",
    "\n",
    "                r = requests.post(os.environ['AZURE_SEARCH_ENDPOINT'] + \"/indexes/\" + value[\"index\"]+\"-vector\" + \"/docs/index\",\n",
    "                                     data=json.dumps(upload_payload), headers=headers, params=params)\n",
    "                \n",
    "                if r.status_code != 200:\n",
    "                    print(r.status_code)\n",
    "                    print(r.text)\n",
    "                else:\n",
    "                    i = i + 1 # 청크의 수 증가\n",
    "                    \n",
    "                    # 문서 안 텍스트 기반 인덱스 업데이트하고 \"벡터화\"로 표시\n",
    "                    upload_payload = {\n",
    "                        \"value\": [\n",
    "                            {\n",
    "                                \"id\": key,\n",
    "                                \"vectorized\": True,\n",
    "                                \"@search.action\": \"merge\"\n",
    "                            },\n",
    "                        ]\n",
    "                    }\n",
    "\n",
    "                    r = requests.post(os.environ['AZURE_SEARCH_ENDPOINT'] + \"/indexes/\" + value[\"index\"]+ \"/docs/index\",\n",
    "                                     data=json.dumps(upload_payload), headers=headers, params=params)\n",
    "                    \n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(\"Exception:\",e)\n",
    "                print(content)\n",
    "                continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f490b7fe-eec2-4c96-a2f2-f8ab0a1b2098",
   "metadata": {},
   "source": [
    "**노트**: 텍스트 기반 인덱스와 벡터 기반 인덱스 동기화\n",
    "문서 변경의 경우 파일에 새 버전이 있으면 Azure Engine이 텍스트 기반 인덱스를 자동으로 업데이트합니다. 이렇게 하면 다음 번에 파일이 검색되면 새로운 벡터 기반 인덱스로 다시 벡터가 덮어씌이게 됩니다.\n",
    "그러나 파일 삭제의 경우 Azure Search 엔진은 원본에서 파일이 삭제되면 텍스트 기반 인덱스의 문서를 삭제하지만 텍스트 기반 인덱스에서 삭제된 ID를 찾고 벡터 기반 인덱스에서 해당 청크를 삭제하는 것은 고정된 일정에 따라 실행되는 스크립트를 코딩해야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f67f3a2-0023-4f5a-b52f-3fb071cfd8e1",
   "metadata": {},
   "source": [
    "이제 벡터 기반 인덱스를 검색하여 질문과 가장 유사한 상위 k개의 청크를 얻습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "61098bb4-33da-4eb4-94cf-503587337aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of results: 3\n"
     ]
    }
   ],
   "source": [
    "vector_indexes = [index+\"-vector\" for index in indexes]\n",
    "\n",
    "k = 10\n",
    "similarity_k = 3\n",
    "ordered_results = get_search_results(QUESTION, vector_indexes,\n",
    "                                        k=k, # Number of results per vector index\n",
    "                                        reranker_threshold=1,\n",
    "                                        vector_search=True, \n",
    "                                        similarity_k=similarity_k,\n",
    "                                        query_vector = embedder.embed_query(QUESTION)\n",
    "                                        )\n",
    "print(\"Number of results:\",len(ordered_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a98a974-0633-499f-a8f0-29bf6242e737",
   "metadata": {},
   "source": [
    "벡터 검색의 경우 LLM에 컨텍스트로 k=5개 이상의 청크(각각 최대 5000자)를 제공하지 않는 것이 좋습니다. 그렇지 않으면 나중에 토큰 제한으로 메모리와 대화를 시도하는 문제가 발생할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7dfb9e39-2542-469d-8f64-4c0c26d79535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 3\n"
     ]
    }
   ],
   "source": [
    "top_docs = []\n",
    "for key,value in ordered_results.items():\n",
    "    location = value[\"location\"] if value[\"location\"] is not None else \"\"\n",
    "    top_docs.append(Document(page_content=value[\"chunk\"], metadata={\"source\": location}))\n",
    "        \n",
    "print(\"Number of chunks:\",len(top_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "880885fe-16bd-44bb-9556-7cb3d4989993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System prompt token count: 1669\n",
      "Max Completion Token count: 2000\n",
      "Combined docs (context) token count: 17556\n",
      "--------\n",
      "Requested token count: 21225\n",
      "Token limit for gpt-4 : 8192\n",
      "Chain Type selected: map_reduce\n"
     ]
    }
   ],
   "source": [
    "# 문서의 토큰 수 계산\n",
    "if(len(top_docs)>0):\n",
    "    tokens_limit = model_tokens_limit(MODEL) # utils.py에 있는 사용자 정의 함수\n",
    "    prompt_tokens = num_tokens_from_string(COMBINE_PROMPT_TEMPLATE) # utils.py에 있는 사용자 정의 함수\n",
    "    context_tokens = num_tokens_from_docs(top_docs) # utils.py에 있는 사용자 정의 함수\n",
    "    \n",
    "    requested_tokens = prompt_tokens + context_tokens + COMPLETION_TOKENS\n",
    "    \n",
    "    chain_type = \"map_reduce\" if requested_tokens > 0.9 * tokens_limit else \"stuff\"  \n",
    "    \n",
    "    print(\"System prompt token count:\",prompt_tokens)\n",
    "    print(\"Max Completion Token count:\", COMPLETION_TOKENS)\n",
    "    print(\"Combined docs (context) token count:\",context_tokens)\n",
    "    print(\"--------\")\n",
    "    print(\"Requested token count:\",requested_tokens)\n",
    "    print(\"Token limit for\", MODEL, \":\", tokens_limit)\n",
    "    print(\"Chain Type selected:\", chain_type)\n",
    "        \n",
    "else:\n",
    "    print(\"NO RESULTS FROM AZURE SEARCH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e232424-c7ba-4153-b23b-fb1fa2ebc64b",
   "metadata": {},
   "source": [
    "이제 LangChain 'qa_with_sources'의 유틸리티 체인을 사용하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "511273b3-256d-4e60-be72-ccd4a74cb885",
   "metadata": {},
   "outputs": [],
   "source": [
    "if chain_type == \"stuff\":\n",
    "    chain = load_qa_with_sources_chain(llm, chain_type=chain_type, \n",
    "                                       prompt=COMBINE_PROMPT)\n",
    "elif chain_type == \"map_reduce\":\n",
    "    chain = load_qa_with_sources_chain(llm, chain_type=chain_type, \n",
    "                                       question_prompt=COMBINE_QUESTION_PROMPT,\n",
    "                                       combine_prompt=COMBINE_PROMPT,\n",
    "                                       return_intermediate_steps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b99a0c19-d48c-41e9-8d6c-6d9f13d29da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 16.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 다른 언어로도 가능합니다. \n",
    "response = chain({\"input_documents\": top_docs, \"question\": QUESTION, \"language\": \"Korean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "37f7fa67-f67b-402e-89e3-266d5d6d21d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "발달상권 가구의 4분기 분기매출에 대한 정보는 제공되지 않았습니다<sup><a href=\"https://holstorage.blob.core.windows.net/arxivcs/230922__etoday.pdf\" target=\"_blank\">[1]</a></sup><sup><a href=\"https://holstorage.blob.core.windows.net/arxivcs/230921_etoday.pdf\" target=\"_blank\">[2]</a></sup><sup><a href=\"https://holstorage.blob.core.windows.net/arxivcs/230920_etoday.pdf\" target=\"_blank\">[3]</a></sup>."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response['output_text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e27c75-bfd9-4304-b2fd-c8e30bcc0558",
   "metadata": {},
   "source": [
    "**참고**: 답변의 높은 정확도와 품질에도 불구하고 COMBINE_PROMPT에 제시된 지침대로 참조가 이루어지지 않는 경우가 있습니다. 이러한 동작은 GPT-3.5 모델을 사용할 때 나타나는데, 이 문제는 노트 5의 말미에 자세히 알아보겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11345374-6420-4b36-b061-795d2a804c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if you want to inspect the results from map_reduce chain type, each top similar chunk summary (k=4 by default)\n",
    "\n",
    "# if chain_type == \"map_reduce\":\n",
    "#     for step in response['intermediate_steps']:\n",
    "#         display(HTML(\"<b>Chunk Summary:</b> \" + step))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f347373a-a5be-473d-b64e-0f6b6dbcd0e0",
   "metadata": {},
   "source": [
    "# Summary\n",
    "##### Azure Cognitive Search의 결과 도출의 대한 요약은 다음과 같습니다:\n",
    "- Azure Cognitive Search를 활용하여 각 인덱스에서 상위 문서를 식별하는 다중 인덱스 텍스트 기반 검색을 수행합니다.\n",
    "- Azure Cognitive Search의 벡터 검색을 이용하여 가장 관련성이 높은 정보 덩어리를 추출합니다.\n",
    "- 그 다음, Azure OpenAI는 추출된 청크를 컨텍스트로 활용하고 내용을 이해한 후 이를 활용하여 최적의 답변을 제공합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hol-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

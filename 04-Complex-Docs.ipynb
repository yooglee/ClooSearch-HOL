{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60ec6048-44e4-4118-b16a-9c4c9cc78a3b",
   "metadata": {},
   "source": [
    "# 규모가 큰 문서 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9281ac79-47cd-49d4-bdd4-7f5c173a947d",
   "metadata": {},
   "source": [
    "이전 단계들에서는 회사에서 흔히 볼 수 있는 다양한 형태의 파일과 데이터 형식에 대한 솔루션을 개발했는데, 이는 사용 사례의 90%를 다루고 있습니다. 그러나 규모가 크고 복잡한 파일을 처리할 때는 앞선 형식으로는 불가능합니다. \n",
    "\n",
    "복잡한 파일의 예시로 수백 페이지에 걸쳐 이미지, 테이블, 양식 등의 형태로 정보를 포함할 수 있는 기술 사양 안내서 또는 제품 설명서가 있으며 또한 문서의 길이와 이미지 또는 테이블의 존재로 인해 복잡해 질 수 있습니다. \n",
    "\n",
    "보통 이러한 파일들은 일반적으로 PDF 형식입니다. 그렇기에 PDF 파일을 더 잘 처리하기 위해서는 각 문서를 특수한 source로 취급하여 페이지 별로 처리하는 보다 [PyPDF library](https://pypi.org/project/pypdf/) 이나 [Azure AI Document Intelligence SDK (former Form Recognizer)](https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/overview?view=doc-intel-3.0.0)를 OpenAI API를 연동하여 문서를 벡터화하고 벡터 기반 인덱스로 콘텐츠를 푸시하는 것이 좋습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15f6044e-463f-4988-bc46-a3c3d641c15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "import langchain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma, FAISS\n",
    "from langchain import OpenAI, VectorDBQA\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "\n",
    "from common.utils import parse_pdf, read_pdf_files, text_to_base64\n",
    "from common.prompts import COMBINE_QUESTION_PROMPT, COMBINE_PROMPT, COMBINE_PROMPT_TEMPLATE\n",
    "from common.utils import (\n",
    "    get_search_results,\n",
    "    model_tokens_limit,\n",
    "    num_tokens_from_docs,\n",
    "    num_tokens_from_string\n",
    ")\n",
    "\n",
    "\n",
    "from IPython.display import Markdown, HTML, display  \n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"credentials.env\")\n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "    \n",
    "os.makedirs(\"data/books/\",exist_ok=True)\n",
    "    \n",
    "\n",
    "BLOB_CONTAINER_NAME = \"books\"\n",
    "BASE_CONTAINER_URL = \"https://holstorage.blob.core.windows.net/\" + BLOB_CONTAINER_NAME + \"/\"\n",
    "LOCAL_FOLDER = \"./data/books/\"\n",
    "\n",
    "MODEL = \"gpt-4-32k\" # options: gpt-35-turbo, gpt-35-turbo-16k, gpt-4, gpt-4-32k\n",
    "\n",
    "os.makedirs(LOCAL_FOLDER,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "331692ba-b68e-4b99-9bae-5057da9a389d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langchain을 활용하여 Azure OpenAI에 연결하는데 필요한 ENV 변수를 설정\n",
    "os.environ[\"OPENAI_API_BASE\"] = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "594ff0d4-56e3-4bed-843d-28c7a092069b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = OpenAIEmbeddings(deployment=\"text-embedding-ada-002\", chunk_size=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb87c647-158c-4f85-b569-5b9462f06c83",
   "metadata": {},
   "source": [
    "## 1 - 벡터 기반 index를 사용한 수동 문서 크래킹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75551868-1546-421b-a14e-e42618d88e61",
   "metadata": {},
   "source": [
    "Within our demo storage account, we have a container named `books`, which holds 5 books of different lengths, languages, and complexities. Let's create a `cogsrch-index-books-vector` and load it with the pages of all these books.\n",
    "\n",
    "We begin by downloading these books to our local machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0999e24b-6a75-4fa1-9a5f-426cf0f0bdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = [\"blockchain_explaination.pdf\",\n",
    "         \"Harry_Potter_the_Sorcerer_Stone1.pdf\",\n",
    "         \"Harry_Potter_the_Sorcerer_Stone2.pdf\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd867b2f-b5a1-443c-aa0a-ce914a66b3c9",
   "metadata": {},
   "source": [
    "Let's download the files to the local `./data/` folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3554f0b7-fee8-4446-a155-5d22dc0f0888",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    }
   ],
   "source": [
    "for book in tqdm(books):\n",
    "    book_url = BASE_CONTAINER_URL + book + os.environ['BLOB_SAS_TOKEN']\n",
    "    urllib.request.urlretrieve(book_url, LOCAL_FOLDER+ book)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788cc0db-9dae-45f2-8943-2b6fa32fcc75",
   "metadata": {},
   "source": [
    "### pyPDF 혹은 AI Documment Intelligence API (Form Recognizer)이란?\n",
    "\n",
    "'utils.py '에는 pdf 파싱(구문 분석) 기능이 있으며, PyPDF 라이브러리를 이용하여 로컬 파일을 파싱할 수 있으며, Azure AI Document Intelligence(Form Form Recognizer)를 이용하여 로컬 또는 from_url PDF 파일을 파싱할 수 있습니다.\n",
    "\n",
    "'form_recognizer= false'인 경우 함수는 python pyPDF 라이브러리를 사용하여 PDF를 구문 분석하게 되며, 이 경우 75%의 시간이 잘 수행됩니다.<br>\n",
    "\n",
    "AI Document Intelligence API(구 Form Recognizer)를 이용한 최적(및 느린) 파싱 방법으로 'form_recognizer=True'를 설정합니다. 사용할 프리빌트 모델을 지정할 수 있으며 기본값은 'model=\"prebuilt- document\"입니다. 다만 테이블, 차트, 도형으로 복잡한 문서를 가지고 있다면 시도해 볼 수 있습니다\n",
    "model=\"prebuilt-layout\", 각 페이지의 뉘앙스를 모두 담아냅니다(물론 시간은 더 오래 걸립니다).\n",
    "\n",
    "**참고: 많은 PDF가 스캔 이미지입니다. 예를 들어, 스캔되어 PDF로 저장된 서명된 계약서는 pyPDF로 파싱되지 않습니다. AI Document Intelligence API만 작동합니다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1c63a2f-7a53-4346-8a1f-483cfd159d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Text from blockchain_explaination.pdf ...\n",
      "Extracting text using PyPDF\n",
      "Parsing took: 0.612723 seconds\n",
      "blockchain_explaination.pdf contained 16 pages\n",
      "\n",
      "Extracting Text from Harry_Potter_the_Sorcerer_Stone1.pdf ...\n",
      "Extracting text using PyPDF\n",
      "Parsing took: 8.683787 seconds\n",
      "Harry_Potter_the_Sorcerer_Stone1.pdf contained 106 pages\n",
      "\n",
      "Extracting Text from Harry_Potter_the_Sorcerer_Stone2.pdf ...\n",
      "Extracting text using PyPDF\n",
      "Parsing took: 7.905338 seconds\n",
      "Harry_Potter_the_Sorcerer_Stone2.pdf contained 67 pages\n",
      "\n"
     ]
    }
   ],
   "source": [
    "book_pages_map = dict()\n",
    "for book in books:\n",
    "    print(\"Extracting Text from\",book,\"...\")\n",
    "    \n",
    "    # Capture the start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Parse the PDF\n",
    "    book_path = LOCAL_FOLDER+book\n",
    "    book_map = parse_pdf(file=book_path, form_recognizer=False, verbose=True)\n",
    "    book_pages_map[book]= book_map\n",
    "    \n",
    "    # Capture the end time and Calculate the elapsed time\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    print(f\"Parsing took: {elapsed_time:.6f} seconds\")\n",
    "    print(f\"{book} contained {len(book_map)} pages\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de0a722-ae0c-4b57-802a-518f5d4d93fd",
   "metadata": {},
   "source": [
    "이제 각각의 책의 랜덤 페이지를 확인하여 파싱이 정확하게 이루어졌는지 확인해 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2a5d62f-b664-4662-a6c9-a1eb2a3c5e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blockchain_explaination.pdf \n",
      " chunk text: 블록체인의 이해 19\n",
      "<그림 Ⅱ-1> 블록체인을 통한 거래 방법\n",
      "자료: Thomson Reuters(2016. 1. 16), “lock-chai ...\n",
      "\n",
      "Harry_Potter_the_Sorcerer_Stone1.pdf \n",
      " chunk text: ׮ .ீ౟, ࣊ ,৬ э਷ ܻݣ যઉ ח ੄ ۈࢎ਷ ઁо যઁ ؍ ࠺ नী, ਋о э੉ Ҋ ۽ ੹೧ ׮פ! ب݃ ੉ ੄ࠛ ܳ ੌନ ୷ೞೞҊ ח  ...\n",
      "\n",
      "Harry_Potter_the_Sorcerer_Stone2.pdf \n",
      " chunk text: ܰܰ ઉաо, ৈ੗ ച੢प ۽ ә൤ ׮ ܳ ੗ ࢲ ܲࡅ ੗Ҵ о ۷ٜ׮ .\"  ಌद ഋ੉ঠ!\" ੉ क ೞҊ ܻܳ ۆ׮ ೘(੄ ৬ զѐী ੗ ਸ  ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for bookname,bookmap in book_pages_map.items():\n",
    "    print(bookname,\"\\n\",\"chunk text:\",bookmap[random.randint(1, 5)][2][:80],\"...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "801c6bc2-467c-4418-aa7e-ef89a1e20e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text using Azure Document Intelligence\n",
      "CPU times: total: 703 ms\n",
      "Wall time: 25.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "book = \"blockchain_explaination.pdf\"\n",
    "book_path = LOCAL_FOLDER+book\n",
    "book_map = parse_pdf(file=book_path, form_recognizer=True, model=\"prebuilt-document\",from_url=False, verbose=True)\n",
    "book_pages_map[book]= book_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "97f9c5bb-c44b-4a4d-9780-591f9f8d128a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blockchain_explaination.pdf \n",
      " chunk text: 18 연구보고서 2018-24\n",
      "발행 및 이체서비스 등 다방면에 걸쳐 다양한 형태로 적용되기 시작하였으며, 금융 분 야뿐만 아니라 지역화폐(Loc ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(book,\"\\n\",\"chunk text:\",book_map[random.randint(1, 5)][2][:80],\"...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c279dfb-4fed-41b8-89e1-0ca2cefbcdc9",
   "metadata": {},
   "source": [
    "위에서 설명한 바와 같이 Azure Document Intelligence는 pyPDF보다 우수한 것으로 입증되었습니다. **제작 시나리오의 경우 Azure Document Intelligence를 지속적으로 사용할 것을 강력히 권장합니다** 이 경우 \"Pre-built-document\", \"Pre-built-layout\" 등 사용 가능한 모델을 현명하게 선택하는 것이 중요합니다. 모델 선택에 대한 자세한 내용은 [여기](https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/choose-model-feature?view=doc-intel-3.0.0) 에서 확인할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5f9b7d-99e6-426d-a47e-343c7e8b492e",
   "metadata": {},
   "source": [
    "## 벡터 기반 인덱스 생성\n",
    "\n",
    "이제 사전 'book_pages_map'에 책의 chunks(각 책의 각 페이지)의 내용이 들어있으므로, 이 내용이 착륙할 Azure Search Engine에 벡터 기반 인덱스를 만들어 보겠습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7d46e7c5-49c4-40f3-bb2d-79a9afeab4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_index_name = \"cogsrch-index-books-vector\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b07e84b-d306-4bc9-9124-e64f252dd7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Azure 벡터 기반 인덱스 생성\n",
    "# Payloads 헤더 설정\n",
    "headers = {'Content-Type': 'application/json','api-key': os.environ['AZURE_SEARCH_KEY']}\n",
    "params = {'api-version': os.environ['AZURE_SEARCH_API_VERSION']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2df4db6b-969b-4b91-963f-9334e17a4e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "index_payload = {\n",
    "    \"name\": book_index_name,\n",
    "    \"fields\": [\n",
    "        {\"name\": \"id\", \"type\": \"Edm.String\", \"key\": \"true\", \"filterable\": \"true\" },\n",
    "        {\"name\": \"title\",\"type\": \"Edm.String\",\"searchable\": \"true\",\"retrievable\": \"true\"},\n",
    "        {\"name\": \"chunk\",\"type\": \"Edm.String\",\"searchable\": \"true\",\"retrievable\": \"true\"},\n",
    "        {\"name\": \"chunkVector\",\"type\": \"Collection(Edm.Single)\",\"searchable\": \"true\",\"retrievable\": \"true\",\"dimensions\": 1536,\"vectorSearchConfiguration\": \"vectorConfig\"},\n",
    "        {\"name\": \"name\", \"type\": \"Edm.String\", \"searchable\": \"true\", \"retrievable\": \"true\", \"sortable\": \"false\", \"filterable\": \"false\", \"facetable\": \"false\"},\n",
    "        {\"name\": \"location\", \"type\": \"Edm.String\", \"searchable\": \"false\", \"retrievable\": \"true\", \"sortable\": \"false\", \"filterable\": \"false\", \"facetable\": \"false\"},\n",
    "        {\"name\": \"page_num\",\"type\": \"Edm.Int32\",\"searchable\": \"false\",\"retrievable\": \"true\"},\n",
    "        \n",
    "    ],\n",
    "    \"vectorSearch\": {\n",
    "        \"algorithmConfigurations\": [\n",
    "            {\n",
    "                \"name\": \"vectorConfig\",\n",
    "                \"kind\": \"hnsw\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"semantic\": {\n",
    "        \"configurations\": [\n",
    "            {\n",
    "                \"name\": \"my-semantic-config\",\n",
    "                \"prioritizedFields\": {\n",
    "                    \"titleField\": {\n",
    "                        \"fieldName\": \"title\"\n",
    "                    },\n",
    "                    \"prioritizedContentFields\": [\n",
    "                        {\n",
    "                            \"fieldName\": \"chunk\"\n",
    "                        }\n",
    "                    ],\n",
    "                    \"prioritizedKeywordsFields\": []\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "r = requests.put(os.environ['AZURE_SEARCH_ENDPOINT'] + \"/indexes/\" + book_index_name,\n",
    "                 data=json.dumps(index_payload), headers=headers, params=params)\n",
    "print(r.status_code)\n",
    "print(r.ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36691ff0-c4c8-49d0-bfa8-3e076ece0ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to debug errors\n",
    "# r.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc7dda9-4725-410e-9465-54f0298fc758",
   "metadata": {},
   "source": [
    "## 벡터 기반 인덱스에 문서의 청크와 벡터 업로드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73e7600-7902-48d4-b199-9d9dc0a17aa0",
   "metadata": {},
   "source": [
    "다음 코드는 각 문서의 청크에 반복되며 Azure Search Rest API 사용하여 해당 벡터가 있는 각 문서를 인덱스에 삽입합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f5c8aa55-1b60-4057-93db-0d4a89993a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading chunks from blockchain_explaination.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:27<00:00,  1.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading chunks from Harry_Potter_the_Sorcerer_Stone1.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 55/106 [01:27<01:21,  1.60s/it]"
     ]
    }
   ],
   "source": [
    "for bookname,bookmap in book_pages_map.items():\n",
    "    print(\"Uploading chunks from\",bookname)\n",
    "    for page in tqdm(bookmap):\n",
    "        try:\n",
    "            page_num = page[0] + 1\n",
    "            content = page[2]\n",
    "            book_url = BASE_CONTAINER_URL + bookname\n",
    "            upload_payload = {\n",
    "                \"value\": [\n",
    "                    {\n",
    "                        \"id\": text_to_base64(bookname + str(page_num)),\n",
    "                        \"title\": f\"{bookname}_page_{str(page_num)}\",\n",
    "                        \"chunk\": content,\n",
    "                        \"chunkVector\": embedder.embed_query(content if content!=\"\" else \"-------\"),\n",
    "                        \"name\": bookname,\n",
    "                        \"location\": book_url,\n",
    "                        \"page_num\": page_num,\n",
    "                        \"@search.action\": \"upload\"\n",
    "                    },\n",
    "                ]\n",
    "            }\n",
    "\n",
    "            r = requests.post(os.environ['AZURE_SEARCH_ENDPOINT'] + \"/indexes/\" + book_index_name + \"/docs/index\",\n",
    "                                 data=json.dumps(upload_payload), headers=headers, params=params)\n",
    "            if r.status_code != 200:\n",
    "                print(r.status_code)\n",
    "                print(r.text)\n",
    "        except Exception as e:\n",
    "            print(\"Exception:\",e)\n",
    "            print(content)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715cddcf-af7b-4006-a047-853fc7a66be3",
   "metadata": {},
   "source": [
    "## Query the Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b408798-5527-44ca-9dba-cad2ee726aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTION = \"해리포터는 누구하고 같이 살고 있어?\"\n",
    "# QUESTION = \"해리포터는 어떤 학교를 어떻게 갔어?\"\n",
    "QUESTION = \"블록체인의 기술적 개념에 대해서 설명해줘\"\n",
    "# QUESTION = \"블록체인의 종류와 특징을 알려줘\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b182ade-0ddd-47a1-b1eb-2cbf435c317f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_indexes = [book_index_name]\n",
    "\n",
    "ordered_results = get_search_results(QUESTION, vector_indexes, \n",
    "                                        k=10,\n",
    "                                        reranker_threshold=1,\n",
    "                                        vector_search=True, \n",
    "                                        similarity_k=10,\n",
    "                                        query_vector = embedder.embed_query(QUESTION)\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd2f3f2-2d66-4bd4-b90b-d30970b71af4",
   "metadata": {},
   "source": [
    "**Note**: that we are picking a larger k=10 since these chunks are NOT of 5000 chars each like prior notebooks, but instead each page is a chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410ff796-dab1-4817-a3a5-82eeff6c0c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETION_TOKENS = 2000\n",
    "llm = AzureChatOpenAI(deployment_name=MODEL, temperature=0.5, max_tokens=COMPLETION_TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744aba20-b3fd-4286-8d58-2ddfccc77734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 10\n"
     ]
    }
   ],
   "source": [
    "top_docs = []\n",
    "for key,value in ordered_results.items():\n",
    "    location = value[\"location\"] if value[\"location\"] is not None else \"\"\n",
    "    top_docs.append(Document(page_content=value[\"chunk\"], metadata={\"source\": location+os.environ['BLOB_SAS_TOKEN']}))\n",
    "        \n",
    "print(\"Number of chunks:\",len(top_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1c4d56-8c2d-47d6-8717-810f156f1c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System prompt token count: 1669\n",
      "Max Completion Token count: 2000\n",
      "Combined docs (context) token count: 8448\n",
      "--------\n",
      "Requested token count: 12117\n",
      "Token limit for gpt-4-32k : 32768\n",
      "Chain Type selected: stuff\n"
     ]
    }
   ],
   "source": [
    "# Calculate number of tokens of our docs\n",
    "if(len(top_docs)>0):\n",
    "    tokens_limit = model_tokens_limit(MODEL) # this is a custom function we created in common/utils.py\n",
    "    prompt_tokens = num_tokens_from_string(COMBINE_PROMPT_TEMPLATE) # this is a custom function we created in common/utils.py\n",
    "    context_tokens = num_tokens_from_docs(top_docs) # this is a custom function we created in common/utils.py\n",
    "    \n",
    "    requested_tokens = prompt_tokens + context_tokens + COMPLETION_TOKENS\n",
    "    \n",
    "    chain_type = \"map_reduce\" if requested_tokens > 0.9 * tokens_limit else \"stuff\"  \n",
    "    \n",
    "    print(\"System prompt token count:\",prompt_tokens)\n",
    "    print(\"Max Completion Token count:\", COMPLETION_TOKENS)\n",
    "    print(\"Combined docs (context) token count:\",context_tokens)\n",
    "    print(\"--------\")\n",
    "    print(\"Requested token count:\",requested_tokens)\n",
    "    print(\"Token limit for\", MODEL, \":\", tokens_limit)\n",
    "    print(\"Chain Type selected:\", chain_type)\n",
    "        \n",
    "else:\n",
    "    print(\"NO RESULTS FROM AZURE SEARCH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cf3a3f-2b4d-4806-8b92-eb982c52b0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if chain_type == \"stuff\":\n",
    "    chain = load_qa_with_sources_chain(llm, chain_type=chain_type, \n",
    "                                       prompt=COMBINE_PROMPT)\n",
    "elif chain_type == \"map_reduce\":\n",
    "    chain = load_qa_with_sources_chain(llm, chain_type=chain_type, \n",
    "                                       question_prompt=COMBINE_QUESTION_PROMPT,\n",
    "                                       combine_prompt=COMBINE_PROMPT,\n",
    "                                       return_intermediate_steps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b412c56-650f-4ca4-a868-9954f83679fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Try with other language as well\n",
    "response = chain({\"input_documents\": top_docs, \"question\": QUESTION, \"language\": \"Korean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f07b08-87bd-4518-b2f2-03ee1096f59f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "블록체인은 P2P(Peer to Peer) 네트워크를 통해 관리되는 분산 데이터베이스의 한 형태로, 거래 정보를 담은 장부를 중앙 서버 한 곳에 저장하는 것이 아니라 블록체인 네트워크에 연결된 여러 컴퓨터에 저장 및 보관하는 기술입니다<sup><a href=\"https://holstorage.blob.core.windows.net/books/blockchain_explaination.pdf?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2024-11-17T10:00:20Z&st=2023-10-17T02:00:20Z&spr=https&sig=A70wSmXw2q4gtqHFKd8h4J54rSkDp41DnyIXTFQ265A%3D\" target=\"_blank\">[1]</a></sup>. 블록체인은 활용되는 목적에 따라 퍼블릭 블록체인, 프라이빗 블록체인, 컨소시엄 블록체인으로 나뉘며 각 블록체인마다 특징이 있습니다<sup><a href=\"https://holstorage.blob.core.windows.net/books/blockchain_explaination.pdf?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2024-11-17T10:00:20Z&st=2023-10-17T02:00:20Z&spr=https&sig=A70wSmXw2q4gtqHFKd8h4J54rSkDp41DnyIXTFQ265A%3D\" target=\"_blank\">[2]</a></sup>.\n",
       "\n",
       "블록체인 기술의 핵심적인 원리 중 하나는 해시함수입니다. 해시함수는 '어떤 데이터를 고정된 길이의 데이터로 변환'하는 것을 의미하며, 이를 통해 원본 데이터를 알아볼 수 없도록 특수한 문자열로 변환이 되는데, 해시함수는 압축이 아니라 단방향 변환이기 때문에 해시값을 이용해서 원본 데이터를 복원할 수 없다는 특징을 가지고 있습니다<sup><a href=\"https://holstorage.blob.core.windows.net/books/blockchain_explaination.pdf?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2024-11-17T10:00:20Z&st=2023-10-17T02:00:20Z&spr=https&sig=A70wSmXw2q4gtqHFKd8h4J54rSkDp41DnyIXTFQ265A%3D\" target=\"_blank\">[1]</a></sup>.\n",
       "\n",
       "또한, 블록체인에서는 거래 정보를 블록에 담아 차례대로 연결하고 이를 모든 참여자가 공유합니다. 이렇게 거래할 때마다 거래 정보가 담긴 블록이 생성되어 계속 연결되면서 모든 참여자의 컴퓨터에 분산 저장되는데, 이를 해킹하여 임의로 수정하거나 위조 또는 변조하려면 전체 참여자의 과반수 이상의 거래 정보를 동시에 수정하여야 하기 때문에 사실상 불가능합니다<sup><a href=\"https://holstorage.blob.core.windows.net/books/blockchain_explaination.pdf?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2024-11-17T10:00:20Z&st=2023-10-17T02:00:20Z&spr=https&sig=A70wSmXw2q4gtqHFKd8h4J54rSkDp41DnyIXTFQ265A%3D\" target=\"_blank\">[3]</a></sup>.\n",
       "\n",
       "머클 트리는 블록체인에 중요한 역할을 하는데, 이는 모든 거래 데이터의 해시값을 머클 루트에 저장하고, 향후 거래내역의 위·변조 여부를 검증할 때, 원본 해시값과 비교를 통하여, 각 거래의 무결성을 검증할 수 있게 합니다<sup><a href=\"https://holstorage.blob.core.windows.net/books/blockchain_explaination.pdf?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2024-11-17T10:00:20Z&st=2023-10-17T02:00:20Z&spr=https&sig=A70wSmXw2q4gtqHFKd8h4J54rSkDp41DnyIXTFQ265A%3D\" target=\"_blank\">[4]</a></sup><sup><a href=\"https://holstorage.blob.core.windows.net/books/blockchain_explaination.pdf?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2024-11-17T10:00:20Z&st=2023-10-17T02:00:20Z&spr=https&sig=A70wSmXw2q4gtqHFKd8h4J54rSkDp41DnyIXTFQ265A%3D\" target=\"_blank\">[5]</a></sup>."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response['output_text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3941796c-7655-4888-a358-8a62e380bd7e",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "이 노트에서는 텍스트 + 벡터 검색인 [Hybrid Search](https://learn.microsoft.com/en-us/azure/search/search-get-started-vector#hybrid-search)를 사용하여 복잡하고 큰 문서를 처리하고 문서에 대한 Q&A를 수행하는 방법에 대해 배웠습니다.\n",
    "\n",
    "또한 Azure Document Intelligence API의 기능과 수동 문서 구문 분석이 필요한 프로덕션 시나리오에 권장되는 이유에 대해서도 배웠습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hol-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

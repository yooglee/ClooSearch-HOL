{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60ec6048-44e4-4118-b16a-9c4c9cc78a3b",
   "metadata": {},
   "source": [
    "# 규모가 큰 문서 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9281ac79-47cd-49d4-bdd4-7f5c173a947d",
   "metadata": {},
   "source": [
    "이전 단계들에서는 회사에서 흔히 볼 수 있는 다양한 형태의 파일과 데이터 형식에 대한 솔루션을 개발했는데, 이는 사용 사례의 90%를 다루고 있습니다. 그러나 규모가 크고 복잡한 파일을 처리할 때는 앞선 형식으로는 불가능합니다. \n",
    "\n",
    "복잡한 파일의 예시로 수백 페이지에 걸쳐 이미지, 테이블, 양식 등의 형태로 정보를 포함할 수 있는 기술 사양 안내서 또는 제품 설명서가 있으며 또한 문서의 길이와 이미지 또는 테이블의 존재로 인해 복잡해 질 수 있습니다. \n",
    "\n",
    "보통 이러한 파일들은 일반적으로 PDF 형식입니다. 그렇기에 PDF 파일을 더 잘 처리하기 위해서는 각 문서를 특수한 source로 취급하여 페이지 별로 처리하는 보다 [PyPDF library](https://pypi.org/project/pypdf/) 이나 [Azure AI Document Intelligence SDK (former Form Recognizer)](https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/overview?view=doc-intel-3.0.0)를 OpenAI API를 연동하여 문서를 벡터화하고 벡터 기반 인덱스로 콘텐츠를 푸시하는 것이 좋습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15f6044e-463f-4988-bc46-a3c3d641c15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "import langchain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma, FAISS\n",
    "from langchain import OpenAI, VectorDBQA\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "\n",
    "from common.utils import parse_pdf, read_pdf_files, text_to_base64\n",
    "from common.prompts import COMBINE_QUESTION_PROMPT, COMBINE_PROMPT, COMBINE_PROMPT_TEMPLATE\n",
    "from common.utils import (\n",
    "    get_search_results,\n",
    "    model_tokens_limit,\n",
    "    num_tokens_from_docs,\n",
    "    num_tokens_from_string\n",
    ")\n",
    "\n",
    "\n",
    "from IPython.display import Markdown, HTML, display  \n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"credentials.env\")\n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "    \n",
    "os.makedirs(\"data/books/\",exist_ok=True)\n",
    "    \n",
    "\n",
    "BLOB_CONTAINER_NAME = \"books\"\n",
    "BASE_CONTAINER_URL = \"https://demodatasetsp.blob.core.windows.net/\" + BLOB_CONTAINER_NAME + \"/\"\n",
    "LOCAL_FOLDER = \"./data/books/\"\n",
    "\n",
    "MODEL = \"gpt-4\" # options: gpt-35-turbo, gpt-35-turbo-16k, gpt-4, gpt-4-32k\n",
    "\n",
    "os.makedirs(LOCAL_FOLDER,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331692ba-b68e-4b99-9bae-5057da9a389d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langchain을 활용하여 Azure OpenAI에 연결하는데 필요한 ENV 변수를 설정\n",
    "os.environ[\"OPENAI_API_BASE\"] = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "594ff0d4-56e3-4bed-843d-28c7a092069b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = OpenAIEmbeddings(deployment=\"text-embedding-ada-002\", chunk_size=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb87c647-158c-4f85-b569-5b9462f06c83",
   "metadata": {},
   "source": [
    "## 1 - 벡터 기반 index를 사용한 수동 문서 크래킹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75551868-1546-421b-a14e-e42618d88e61",
   "metadata": {},
   "source": [
    "Within our demo storage account, we have a container named `books`, which holds 5 books of different lengths, languages, and complexities. Let's create a `cogsrch-index-books-vector` and load it with the pages of all these books.\n",
    "\n",
    "We begin by downloading these books to our local machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0999e24b-6a75-4fa1-9a5f-426cf0f0bdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = [\"Harry_Potter_the_Sorcerer_Stone1.pdf\", \n",
    "         \"Harry_Potter_the_Sorcerer_Stone2.pdf\",\n",
    "         \"Harry_Potter_Chamber_of_Secrets1.pdf\",\n",
    "         \"Harry_Potter_Chamber_of_Secrets2.pdf\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd867b2f-b5a1-443c-aa0a-ce914a66b3c9",
   "metadata": {},
   "source": [
    "Let's download the files to the local `./data/` folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3554f0b7-fee8-4446-a155-5d22dc0f0888",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  1.73it/s]\n"
     ]
    }
   ],
   "source": [
    "for book in tqdm(books):\n",
    "    book_url = BASE_CONTAINER_URL + book + os.environ['BLOB_SAS_TOKEN']\n",
    "    urllib.request.urlretrieve(book_url, LOCAL_FOLDER+ book)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788cc0db-9dae-45f2-8943-2b6fa32fcc75",
   "metadata": {},
   "source": [
    "### pyPDF 혹은 AI Documment Intelligence API (Form Recognizer)이란?\n",
    "\n",
    "In `utils.py` there is a **parse_pdf()** function. This utility function can parse local files using PyPDF library and can also parse local or from_url PDFs files using Azure AI Document Intelligence (Former Form Recognizer).\n",
    "\n",
    "If `form_recognizer=False`, the function will parse the PDF using the python pyPDF library, which 75% of the time does a good job.<br>\n",
    "\n",
    "Setting `form_recognizer=True`, is the best (and slower) parsing method using AI Documment Intelligence API (former known as Form Recognizer). You can specify the prebuilt model to use, the default is `model=\"prebuilt-document\"`. However, if you have a complex document with tables, charts and figures , you can try\n",
    "`model=\"prebuilt-layout\"`, and it will capture all of the nuances of each page (it takes longer of course).\n",
    "\n",
    "**Note: Many PDFs are scanned images. For example, any signed contract that was scanned and saved as PDF will NOT be parsed by pyPDF. Only AI Documment Intelligence API will work.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1c63a2f-7a53-4346-8a1f-483cfd159d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Text from Azure_Cognitive_Search_Documentation.pdf ...\n",
      "Extracting text using PyPDF\n",
      "Parsing took: 35.475175 seconds\n",
      "Azure_Cognitive_Search_Documentation.pdf contained 1947 pages\n",
      "\n",
      "Extracting Text from Boundaries_When_to_Say_Yes_How_to_Say_No_to_Take_Control_of_Your_Life.pdf ...\n",
      "Extracting text using PyPDF\n",
      "Parsing took: 1.757536 seconds\n",
      "Boundaries_When_to_Say_Yes_How_to_Say_No_to_Take_Control_of_Your_Life.pdf contained 357 pages\n",
      "\n",
      "Extracting Text from Fundamentals_of_Physics_Textbook.pdf ...\n",
      "Extracting text using PyPDF\n",
      "Parsing took: 105.944826 seconds\n",
      "Fundamentals_of_Physics_Textbook.pdf contained 1450 pages\n",
      "\n",
      "Extracting Text from Made_To_Stick.pdf ...\n",
      "Extracting text using PyPDF\n",
      "Parsing took: 8.193571 seconds\n",
      "Made_To_Stick.pdf contained 225 pages\n",
      "\n",
      "Extracting Text from Pere_Riche_Pere_Pauvre.pdf ...\n",
      "Extracting text using PyPDF\n",
      "Parsing took: 1.212609 seconds\n",
      "Pere_Riche_Pere_Pauvre.pdf contained 225 pages\n",
      "\n"
     ]
    }
   ],
   "source": [
    "book_pages_map = dict()\n",
    "for book in books:\n",
    "    print(\"Extracting Text from\",book,\"...\")\n",
    "    \n",
    "    # Capture the start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Parse the PDF\n",
    "    book_path = LOCAL_FOLDER+book\n",
    "    book_map = parse_pdf(file=book_path, form_recognizer=False, verbose=True)\n",
    "    book_pages_map[book]= book_map\n",
    "    \n",
    "    # Capture the end time and Calculate the elapsed time\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    print(f\"Parsing took: {elapsed_time:.6f} seconds\")\n",
    "    print(f\"{book} contained {len(book_map)} pages\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de0a722-ae0c-4b57-802a-518f5d4d93fd",
   "metadata": {},
   "source": [
    "Now let's check a random page of each book to make sure the parsing was done correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2a5d62f-b664-4662-a6c9-a1eb2a3c5e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure_Cognitive_Search_Documentation.pdf \n",
      " chunk text: What's new in Cognitive Search\n",
      "Preview features in Cognitive Search ...\n",
      "\n",
      "Boundaries_When_to_Say_Yes_How_to_Say_No_to_Take_Control_of_Your_Life.pdf \n",
      " chunk text: 22\n",
      "11:50 P.M.\n",
      "Lying in bed, Sherrie couldn’t tell which was greater, her lone-\n",
      "l ...\n",
      "\n",
      "Fundamentals_of_Physics_Textbook.pdf \n",
      " chunk text: xxiPREFACEINSTRUCTOR SUPPLEMENTSInstructor’s Solutions Manualby Sen-Ben Liao, La ...\n",
      "\n",
      "Made_To_Stick.pdf \n",
      " chunk text: fare airline\" and the other stories in this chapter  aren't simple be- \n",
      "cause th ...\n",
      "\n",
      "Pere_Riche_Pere_Pauvre.pdf \n",
      " chunk text: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~~~\n",
      "~~ ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for bookname,bookmap in book_pages_map.items():\n",
    "    print(bookname,\"\\n\",\"chunk text:\",bookmap[random.randint(10, 50)][2][:80],\"...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "801c6bc2-467c-4418-aa7e-ef89a1e20e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text using Azure Document Intelligence\n",
      "CPU times: user 11.6 s, sys: 212 ms, total: 11.8 s\n",
      "Wall time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "book = \"Harry_Potter_the_Sorcerer_Stone1.pdf\"\n",
    "book_path = LOCAL_FOLDER+book\n",
    "book_map = parse_pdf(file=book_path, form_recognizer=True, model=\"prebuilt-document\",from_url=False, verbose=True)\n",
    "book_pages_map[book]= book_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97f9c5bb-c44b-4a4d-9780-591f9f8d128a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pere_Riche_Pere_Pauvre.pdf \n",
      " chunk text: Ces deux cheminements de vie exigeaient de l'instruction mais les matières à étu ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(book,\"\\n\",\"chunk text:\",book_map[random.randint(10, 50)][2][:80],\"...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c279dfb-4fed-41b8-89e1-0ca2cefbcdc9",
   "metadata": {},
   "source": [
    "As demonstrated above, Azure Document Intelligence proves to be superior to pyPDF. **For production scenarios, we strongly recommend using Azure Document Intelligence consistently**. When doing so, it's important to make a wise choice between the available models, such as \"prebuilt-document,\" \"prebuilt-layout,\" or others. You can find more information on model selection [HERE](https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/choose-model-feature?view=doc-intel-3.0.0).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5f9b7d-99e6-426d-a47e-343c7e8b492e",
   "metadata": {},
   "source": [
    "## 벡터 기반 인덱스 생성\n",
    "\n",
    "\n",
    "Now that we have the content of the book's chunks (each page of each book) in the dictionary `book_pages_map`, let's create the Vector-based index in our Azure Search Engine where this content is going to land"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d46e7c5-49c4-40f3-bb2d-79a9afeab4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_index_name = \"cogsrch-index-books-vector\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b07e84b-d306-4bc9-9124-e64f252dd7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Azure 벡터 기반 인덱스 생성\n",
    "# Payloads 헤더 설정\n",
    "headers = {'Content-Type': 'application/json','api-key': os.environ['AZURE_SEARCH_KEY']}\n",
    "params = {'api-version': os.environ['AZURE_SEARCH_API_VERSION']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2df4db6b-969b-4b91-963f-9334e17a4e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "index_payload = {\n",
    "    \"name\": book_index_name,\n",
    "    \"fields\": [\n",
    "        {\"name\": \"id\", \"type\": \"Edm.String\", \"key\": \"true\", \"filterable\": \"true\" },\n",
    "        {\"name\": \"title\",\"type\": \"Edm.String\",\"searchable\": \"true\",\"retrievable\": \"true\"},\n",
    "        {\"name\": \"chunk\",\"type\": \"Edm.String\",\"searchable\": \"true\",\"retrievable\": \"true\"},\n",
    "        {\"name\": \"chunkVector\",\"type\": \"Collection(Edm.Single)\",\"searchable\": \"true\",\"retrievable\": \"true\",\"dimensions\": 1536,\"vectorSearchConfiguration\": \"vectorConfig\"},\n",
    "        {\"name\": \"name\", \"type\": \"Edm.String\", \"searchable\": \"true\", \"retrievable\": \"true\", \"sortable\": \"false\", \"filterable\": \"false\", \"facetable\": \"false\"},\n",
    "        {\"name\": \"location\", \"type\": \"Edm.String\", \"searchable\": \"false\", \"retrievable\": \"true\", \"sortable\": \"false\", \"filterable\": \"false\", \"facetable\": \"false\"},\n",
    "        {\"name\": \"page_num\",\"type\": \"Edm.Int32\",\"searchable\": \"false\",\"retrievable\": \"true\"},\n",
    "        \n",
    "    ],\n",
    "    \"vectorSearch\": {\n",
    "        \"algorithmConfigurations\": [\n",
    "            {\n",
    "                \"name\": \"vectorConfig\",\n",
    "                \"kind\": \"hnsw\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"semantic\": {\n",
    "        \"configurations\": [\n",
    "            {\n",
    "                \"name\": \"my-semantic-config\",\n",
    "                \"prioritizedFields\": {\n",
    "                    \"titleField\": {\n",
    "                        \"fieldName\": \"title\"\n",
    "                    },\n",
    "                    \"prioritizedContentFields\": [\n",
    "                        {\n",
    "                            \"fieldName\": \"chunk\"\n",
    "                        }\n",
    "                    ],\n",
    "                    \"prioritizedKeywordsFields\": []\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "r = requests.put(os.environ['AZURE_SEARCH_ENDPOINT'] + \"/indexes/\" + book_index_name,\n",
    "                 data=json.dumps(index_payload), headers=headers, params=params)\n",
    "print(r.status_code)\n",
    "print(r.ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36691ff0-c4c8-49d0-bfa8-3e076ece0ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to debug errors\n",
    "# r.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc7dda9-4725-410e-9465-54f0298fc758",
   "metadata": {},
   "source": [
    "## 벡터 기반 인덱스에 문서의 청크와 벡터 업로드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73e7600-7902-48d4-b199-9d9dc0a17aa0",
   "metadata": {},
   "source": [
    "다음 코드는 각 문서의 청크에 반복되며 Azure Search Rest API 사용하여 해당 벡터가 있는 각 문서를 인덱스에 삽입합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5c8aa55-1b60-4057-93db-0d4a89993a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading chunks from Azure_Cognitive_Search_Documentation.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1947/1947 [05:19<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading chunks from Boundaries_When_to_Say_Yes_How_to_Say_No_to_Take_Control_of_Your_Life.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 357/357 [00:59<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading chunks from Fundamentals_of_Physics_Textbook.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1450/1450 [04:36<00:00,  5.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading chunks from Made_To_Stick.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [00:39<00:00,  5.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading chunks from Pere_Riche_Pere_Pauvre.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [00:39<00:00,  5.73it/s]\n"
     ]
    }
   ],
   "source": [
    "for bookname,bookmap in book_pages_map.items():\n",
    "    print(\"Uploading chunks from\",bookname)\n",
    "    for page in tqdm(bookmap):\n",
    "        try:\n",
    "            page_num = page[0] + 1\n",
    "            content = page[2]\n",
    "            book_url = BASE_CONTAINER_URL + bookname\n",
    "            upload_payload = {\n",
    "                \"value\": [\n",
    "                    {\n",
    "                        \"id\": text_to_base64(bookname + str(page_num)),\n",
    "                        \"title\": f\"{bookname}_page_{str(page_num)}\",\n",
    "                        \"chunk\": content,\n",
    "                        \"chunkVector\": embedder.embed_query(content if content!=\"\" else \"-------\"),\n",
    "                        \"name\": bookname,\n",
    "                        \"location\": book_url,\n",
    "                        \"page_num\": page_num,\n",
    "                        \"@search.action\": \"upload\"\n",
    "                    },\n",
    "                ]\n",
    "            }\n",
    "\n",
    "            r = requests.post(os.environ['AZURE_SEARCH_ENDPOINT'] + \"/indexes/\" + book_index_name + \"/docs/index\",\n",
    "                                 data=json.dumps(upload_payload), headers=headers, params=params)\n",
    "            if r.status_code != 200:\n",
    "                print(r.status_code)\n",
    "                print(r.text)\n",
    "        except Exception as e:\n",
    "            print(\"Exception:\",e)\n",
    "            print(content)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715cddcf-af7b-4006-a047-853fc7a66be3",
   "metadata": {},
   "source": [
    "## Query the Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b408798-5527-44ca-9dba-cad2ee726aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION = \"해리포터는 누구하고 같이 살고 있어?\"\n",
    "# QUESTION = \"해리포터는 어떤 학교를 어떻게 갔어?\"\n",
    "# QUESTION = \"볼드모트가 누구야?\"\n",
    "# QUESTION = \"볼드모트가 원하는게 뭐야?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b182ade-0ddd-47a1-b1eb-2cbf435c317f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_indexes = [book_index_name]\n",
    "\n",
    "ordered_results = get_search_results(QUESTION, vector_indexes, \n",
    "                                        k=10,\n",
    "                                        reranker_threshold=1,\n",
    "                                        vector_search=True, \n",
    "                                        similarity_k=10,\n",
    "                                        query_vector = embedder.embed_query(QUESTION)\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd2f3f2-2d66-4bd4-b90b-d30970b71af4",
   "metadata": {},
   "source": [
    "**Note**: that we are picking a larger k=10 since these chunks are NOT of 5000 chars each like prior notebooks, but instead each page is a chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "410ff796-dab1-4817-a3a5-82eeff6c0c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETION_TOKENS = 1000\n",
    "llm = AzureChatOpenAI(deployment_name=MODEL, temperature=0.5, max_tokens=COMPLETION_TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "744aba20-b3fd-4286-8d58-2ddfccc77734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 10\n"
     ]
    }
   ],
   "source": [
    "top_docs = []\n",
    "for key,value in ordered_results.items():\n",
    "    location = value[\"location\"] if value[\"location\"] is not None else \"\"\n",
    "    top_docs.append(Document(page_content=value[\"chunk\"], metadata={\"source\": location+os.environ['BLOB_SAS_TOKEN']}))\n",
    "        \n",
    "print(\"Number of chunks:\",len(top_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db1c4d56-8c2d-47d6-8717-810f156f1c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System prompt token count: 1669\n",
      "Max Completion Token count: 1000\n",
      "Combined docs (context) token count: 3529\n",
      "--------\n",
      "Requested token count: 6198\n",
      "Token limit for gpt-35-turbo-16k : 16384\n",
      "Chain Type selected: stuff\n"
     ]
    }
   ],
   "source": [
    "# Calculate number of tokens of our docs\n",
    "if(len(top_docs)>0):\n",
    "    tokens_limit = model_tokens_limit(MODEL) # this is a custom function we created in common/utils.py\n",
    "    prompt_tokens = num_tokens_from_string(COMBINE_PROMPT_TEMPLATE) # this is a custom function we created in common/utils.py\n",
    "    context_tokens = num_tokens_from_docs(top_docs) # this is a custom function we created in common/utils.py\n",
    "    \n",
    "    requested_tokens = prompt_tokens + context_tokens + COMPLETION_TOKENS\n",
    "    \n",
    "    chain_type = \"map_reduce\" if requested_tokens > 0.9 * tokens_limit else \"stuff\"  \n",
    "    \n",
    "    print(\"System prompt token count:\",prompt_tokens)\n",
    "    print(\"Max Completion Token count:\", COMPLETION_TOKENS)\n",
    "    print(\"Combined docs (context) token count:\",context_tokens)\n",
    "    print(\"--------\")\n",
    "    print(\"Requested token count:\",requested_tokens)\n",
    "    print(\"Token limit for\", MODEL, \":\", tokens_limit)\n",
    "    print(\"Chain Type selected:\", chain_type)\n",
    "        \n",
    "else:\n",
    "    print(\"NO RESULTS FROM AZURE SEARCH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "62cf3a3f-2b4d-4806-8b92-eb982c52b0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if chain_type == \"stuff\":\n",
    "    chain = load_qa_with_sources_chain(llm, chain_type=chain_type, \n",
    "                                       prompt=COMBINE_PROMPT)\n",
    "elif chain_type == \"map_reduce\":\n",
    "    chain = load_qa_with_sources_chain(llm, chain_type=chain_type, \n",
    "                                       question_prompt=COMBINE_QUESTION_PROMPT,\n",
    "                                       combine_prompt=COMBINE_PROMPT,\n",
    "                                       return_intermediate_steps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b412c56-650f-4ca4-a868-9954f83679fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.3 ms, sys: 18 µs, total: 43.3 ms\n",
      "Wall time: 13.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Try with other language as well\n",
    "response = chain({\"input_documents\": top_docs, \"question\": QUESTION, \"language\": \"English\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63f07b08-87bd-4518-b2f2-03ee1096f59f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To push documents with vectors to an index using the Python SDK, you can use the following example:\n",
       "\n",
       "Python\n",
       "```\n",
       "from azure.core.credentials import AzureKeyCredential\n",
       "from azure.search.documents import SearchClient\n",
       "\n",
       "# Set up the necessary credentials and endpoint\n",
       "endpoint = \"your_search_service_endpoint\"\n",
       "key = \"your_search_service_api_key\"\n",
       "index_name = \"your_index_name\"\n",
       "\n",
       "# Create a search client\n",
       "search_client = SearchClient(endpoint=endpoint, index_name=index_name, credential=AzureKeyCredential(key))\n",
       "\n",
       "# Define your documents with vectors\n",
       "documents = [\n",
       "    {\n",
       "        \"@search.action\": \"upload\",\n",
       "        \"id\": \"1\",\n",
       "        \"text\": \"example document\",\n",
       "        \"vector\": [0.1, 0.2, 0.3]\n",
       "    },\n",
       "    {\n",
       "        \"@search.action\": \"upload\",\n",
       "        \"id\": \"2\",\n",
       "        \"text\": \"another document\",\n",
       "        \"vector\": [0.4, 0.5, 0.6]\n",
       "    }\n",
       "]\n",
       "\n",
       "# Upload the documents to the index\n",
       "result = search_client.upload_documents(documents=documents)\n",
       "\n",
       "# Check if the upload succeeded\n",
       "for upload_result in result:\n",
       "    print(f\"Upload of document {upload_result.key} succeeded: {upload_result.succeeded}\")\n",
       "```\n",
       "\n",
       "This example demonstrates how to create a search client, define documents with vectors, and upload them to the specified index using the `upload_documents` method of the search client.\n",
       "\n",
       "[1]<sup><a href=\"https://demodatasetsp.blob.core.windows.net/books/Azure_Cognitive_Search_Documentation.pdf?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\" target=\"_blank\">Source</a></sup>\n",
       "\n",
       "Let me know if there is anything else I can help you with."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response['output_text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3941796c-7655-4888-a358-8a62e380bd7e",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "이 노트에서는 텍스트 + 벡터 검색인 [Hybrid Search](https://learn.microsoft.com/en-us/azure/search/search-get-started-vector#hybrid-search)를 사용하여 복잡하고 큰 문서를 처리하고 문서에 대한 Q&A를 수행하는 방법에 대해 배웠습니다.\n",
    "\n",
    "또한 Azure Document Intelligence API의 기능과 수동 문서 구문 분석이 필요한 프로덕션 시나리오에 권장되는 이유에 대해서도 배웠습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
